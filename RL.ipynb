{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL Asignment 1",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y55yyb0hWSWz"
      },
      "source": [
        "# Reinforcement Learning\n",
        "###Mina Rahmanian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPMwCW__Wj_l"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1- Defining the required Libraries, Functions and do the necessary Preprocessing\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The update rules for each player ğ‘— are:\n",
        "\n",
        "$p{^{j}_c}(k+1) = p{^{j}_c}(k) + \\alpha r^{j}(k) \\Big[1 - p{^{j}_c}(k)\\Big]$,      if action c is taken at time t\n",
        "\n",
        "\n",
        "$p{^{j}_o}(k+1) = p{^{j}_o}(k) - \\alpha r^{j}(k)p{^{j}_o}(k)$,    ğ‘“ğ‘œğ‘Ÿ ğ‘ğ‘™ğ‘™ ğ‘œğ‘¡â„ğ‘’ğ‘Ÿ ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  ğ‘œ â‰  ğ‘\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGON3rTAIipM"
      },
      "source": [
        "\"\"\" Libraries \"\"\"\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Defining all three games in one function.\n",
        "This function Returns a dictionary object of parameters for each game.\n",
        "\"\"\"\n",
        "\n",
        "def Game(NumG):\n",
        "  \n",
        "        #  Numg values (Number of Game) [1-3] indicate the set of parameters to be returned, where\n",
        "        #  1 is prisoner's dilemma\n",
        "        #  2 is matching pennies\n",
        "        #  3 is rock paper scissors  \n",
        "\n",
        "    # Reward matrice of prisoner's dilemma\n",
        "     PrsDil_R = np.array([\n",
        "        [5, 0],\n",
        "        [10, 1]\n",
        "        ])\n",
        "    \n",
        "    # Reward matrice of matching pennies\n",
        "     MatPen_R = np.array([\n",
        "        [1, -1],\n",
        "        [-1, 1]\n",
        "        ])\n",
        "     \n",
        "     # Reward matrice of rock paper scissors\n",
        "     RoPaSci_R = np.array([\n",
        "        [0, -1, 1],\n",
        "        [1, 0, -1],\n",
        "        [-1, 1, 0]\n",
        "        ])\n",
        "\n",
        "     # Policy updating matrices:\n",
        "     # Contain arrays which are used during the policy update equation, where 1 in the array\n",
        "     # corresponds to the action to be increased and 0 indicates the action(s) to be decreased\n",
        "     # in the policy update.    \n",
        "     Unit2d = np.array([\n",
        "        [1, 0],\n",
        "        [0, 1]\n",
        "        ])\n",
        "     \n",
        "     Unit3d = np.array([\n",
        "        [1, 0, 0],\n",
        "        [0, 1, 0],\n",
        "        [0, 0, 1]\n",
        "        ])\n",
        "\n",
        "\n",
        "     # Graph labels:\n",
        "     # Arrays of labels for graphing the experimental results for each game.\n",
        "     if NumG < 3:\n",
        "        GraphLabels1 = [\n",
        "        ['Prisoner\\'s Dilemma', 'Player1 Prb(Coop)', 'Player2 Prb(Coop)'],\n",
        "        ['Matching Pennies', 'Player1 Prb(Head)', 'Player2 Prb(Head)'],\n",
        "        ]\n",
        "     else:\n",
        "        GraphLabels1 = [\n",
        "        ['Prisoner\\'s Dilemma', 'Player1 Prb(Coop)', 'Player2 Prb(Coop)'],\n",
        "        ['Matching Pennies', 'Player1 Prb(Head)', 'Player2 Prb(Head)'],\n",
        "        ['Rock Paper Scissors', 'Prb(Rock)', 'Prb(Paper)','Prb(Scissor)'],\n",
        "        ]\n",
        "\n",
        "     GraphLabels2 = ['Value of Players','Iteration']\n",
        "\n",
        "\n",
        "     # Logical (switch) statement to determine parameter selection.\n",
        "     if NumG == 1: # Prisoner's Dilemma\n",
        "        R1 = PrsDil_R\n",
        "        R2 = PrsDil_R.T\n",
        "        Unit = Unit2d\n",
        "     elif NumG == 2: # Matching Pennies\n",
        "        R1 = MatPen_R\n",
        "        R2 = -MatPen_R\n",
        "        Unit = Unit2d\n",
        "     elif NumG == 3: # Rock Paper Scissors\n",
        "        R1 = RoPaSci_R\n",
        "        R2 = -RoPaSci_R\n",
        "        Unit = Unit3d\n",
        "     else:           # Default\n",
        "        print('Enter the Game {1 2 3}')\n",
        "\n",
        "\n",
        "     return {'r1': R1, 'r2': R2, 'Unit': Unit, 'labels1': GraphLabels1[NumG-1], 'labels2': GraphLabels2}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        " Since we need to play for different intial policies, we define a function \n",
        " to generate different initial policies for each trial of each game.\n",
        "\n",
        "\"\"\"\n",
        "def InitPolicies(size, trial, game):\n",
        "    \n",
        "    # Returns a Initial Policy p_i for each player with a random uniform distribution scaled to [0, 1).\n",
        "    # It is then normalize to sum to 1 for trial 1 to 5. \n",
        "    # 'size' is the number of actions in the policies, 'trial' is the number of playing \n",
        "    # and 'game' is the number of game {1 2 3}\n",
        "    \n",
        "    pi1 = np.abs(np.random.randn(len(R1))).astype(np.half)\n",
        "    pi2 = np.abs(np.random.randn(len(R1))).astype(np.half)\n",
        "\n",
        "    return pi1/pi1.sum(), pi2/pi2.sum()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        " Normalize the policies to ensure the values are in [0,1)\n",
        "\"\"\"\n",
        "def NormPolicies(p1, p2):\n",
        " \n",
        "       # p1: an array representing player 1's policy\n",
        "       # p2: an array representing player 2's policy\n",
        "    \n",
        "    # Restrict the polices to [0, 1].\n",
        "    p1 = np.clip(p1, a_min=0, a_max=1)\n",
        "    p2 = np.clip(p2, a_min=0, a_max=1)\n",
        "    \n",
        "    # Restrict the polices to sum to 1, and the resulting normalized polices to [0, 1].\n",
        "    p1 = np.clip(p1/p1.sum(), a_min=0, a_max=1)\n",
        "    p2 = np.clip(p2/p2.sum(), a_min=0, a_max=1)\n",
        "    \n",
        "    return p1, p2  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbQFg9VniWZ_"
      },
      "source": [
        "2- The main algorithm and policy update loop is given here, this include the modification for the added Expectation term for all games\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The update rules for each player ğ‘— are:\n",
        "\n",
        "$p{^{j}_c}(k+1) = p{^{j}_c}(k) + \\alpha r^{j}(k) \\Big[1 - p{^{j}_c}(k)\\Big]$,      if action c is taken at time t\n",
        "\n",
        "\n",
        "$p{^{j}_o}(k+1) = p{^{j}_o}(k) - \\alpha r^{j}(k)p{^{j}_o}(k)$,    ğ‘“ğ‘œğ‘Ÿ ğ‘ğ‘™ğ‘™ ğ‘œğ‘¡â„ğ‘’ğ‘Ÿ ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  ğ‘œ â‰  ğ‘\n",
        "\n",
        "\n",
        "---\n",
        "Modify the algorithm so another term is added:\n",
        "\n",
        "$p{^{j}_c}(K+1) = p{^{j}_c}(K) + \\alpha r^{j}(K) \\Big[1 - p{^{j}_c}(K)\\Big] + \\alpha \\Big\\{E \\Big[p{^{j}_c}(K)\\Big] - p{^{j}_c}(K)\\Big\\}$, ğ‘–ğ‘“ ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘› ğ‘ ğ‘–ğ‘  ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘› ğ‘ğ‘¡ ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘¡\n",
        "\n",
        "\n",
        "$p{^{j}_o}(K+1) = p{^{j}_o}(K) - \\alpha r^{j}(K)p{^{j}_o}(K) + \\alpha \\Big\\{E \\Big[p{^{j}_o}(K)\\Big] - p{^{j}_o}(K)\\Big\\}$, ğ‘“ğ‘œğ‘Ÿ ğ‘ğ‘™ğ‘™ ğ‘œğ‘¡â„ğ‘’ğ‘Ÿ ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  ğ‘œ â‰  ğ‘\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm2OKzrHPJkP"
      },
      "source": [
        "\n",
        "# The random generator with the ability to reproduce the Initial Policies for \n",
        "# different runs\n",
        "np.random.seed(1000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Learning Parameters\n",
        "    Iteration = 40000\n",
        "    Alpha = 0.01\n",
        "    \n",
        "    # Selecting True yields the policy update with the expected value term, and\n",
        "    # False without.\n",
        "    ExpectedValue = False\n",
        "    \n",
        "\n",
        "    # Get final policies for each game and graph the results.\n",
        "    for NumG in range(1,4):\n",
        "\n",
        "        # Initialize pyplot's subplot feature that will show graphs for each Trial\n",
        "        if NumG < 3: # For the first two games\n",
        "            fig, ax = plt.subplots(1,5,figsize=(17,3), constrained_layout=True)\n",
        "        else: # For Rock Paper Scissors we a graph for each player\n",
        "            plt.rcParams.update({'font.size': 8})\n",
        "            fig = plt.figure(figsize=(19.,3.3), dpi=300, linewidth=0.2)\n",
        "\n",
        "\n",
        "        # Initialize pyplots subplot for Value function graph for each Trial\n",
        "        fig2, ax2 = plt.subplots(1,5,figsize=(17,3), constrained_layout=True)\n",
        "\n",
        "\n",
        "        # GAME PARAMETERS\n",
        "\n",
        "        # Get the parameters for the game.\n",
        "        R1, R2, Unit, GraphLabels1, GraphLabels2 = Game(NumG).values()\n",
        "\n",
        "        n_Choices = len(R1) # Number of possible actions in each player's policy\n",
        "\n",
        "        Choices = np.arange(n_Choices) # An array of indexes corresponding to the possible actions\n",
        "        print('\\n********************************************************************************************')\n",
        "        print('\\t\\t\\t\\t      %s ' % (GraphLabels1[0]))\n",
        "        print('********************************************************************************************\\n')\n",
        "\n",
        "        # Run each Game for 5 Trials\n",
        "        for Trial in range(5):\n",
        "            \n",
        "            # A Separate 3 dimensional graph axes is defined here for RPS Game\n",
        "            if NumG == 3:\n",
        "                ax = fig.add_subplot(1, 5, Trial+1, projection='3d')\n",
        "\n",
        "            # EXPERIMENTAL TRIAL PARAMETERS\n",
        "\n",
        "            # Initialize lists to store the data points to be plotted.\n",
        "            pts_x = []\n",
        "            pts_y = []\n",
        "            pts_z = []\n",
        "            V1 = []\n",
        "            V2 = []\n",
        "            Itr = []\n",
        "\n",
        "            # Initialize the expected value terms of the update function to zeros\n",
        "            Ex1, Ex2 = np.zeros(n_Choices), np.zeros(n_Choices)\n",
        "\n",
        "            # Get the inital policies.\n",
        "            p1, p2 = InitPolicies(n_Choices, Trial, NumG)\n",
        "\n",
        "            # Show the initial policies for each trial for each game.\n",
        "            print('@@@@@ Trial %d @@@@@' %(Trial + 1))\n",
        "            print('\\nInitial policy:\\n  player 1', np.round(p1, 4),'\\n  player 2', np.round(p2, 4))\n",
        "\n",
        "            # Time execution.\n",
        "            start = time.time()\n",
        "\n",
        "            # Initialize the experimentally calculated value for the game for each player\n",
        "            value_pl1 = 0\n",
        "            value_pl2 = 0\n",
        "            It = 0\n",
        "\n",
        "            # Choose an action, get a reward and update the policies for 50000 iterations.\n",
        "            for _ in range(Iteration):\n",
        "\n",
        "                # Pick an action for each player randomly using their policy as the distribution function.\n",
        "                Action1 = np.random.choice(Choices, p=p1)\n",
        "                Action2 = np.random.choice(Choices, p=p2)\n",
        "\n",
        "                # Determine the reward for each player.\n",
        "                r1 = R1[Action1, Action2]\n",
        "                r2 = R2[Action1, Action2]    \n",
        "\n",
        "                # Keep a running total of the game's value for each player.\n",
        "                value_pl1 += r1\n",
        "                value_pl2 += r2\n",
        "                # Value function after each Iteration\n",
        "                Val1 = value_pl1/Iteration\n",
        "                Val2 = value_pl2/Iteration\n",
        "                It += 1\n",
        "\n",
        "                # Update the policy for each player\n",
        "                # Both actions are incorporated in the update las through \n",
        "                # through the Unit array  \n",
        "                p1 = p1 + Alpha * r1 * (Unit[Action1] - p1)\n",
        "                p2 = p2 + Alpha * r2 * (Unit[Action2] - p2)\n",
        "\n",
        "                # Added the expected value term if required\n",
        "                if ExpectedValue:\n",
        "                    p1 = p1 + Alpha * (Ex1 - p1)\n",
        "                    p2 = p2 + Alpha * (Ex2 - p2)\n",
        "\n",
        "\n",
        "                # Normalize the policies\n",
        "                p1, p2 = NormPolicies(p1, p2)\n",
        "\n",
        "                # Update the expected value term with the previous policy\n",
        "                Ex1 = Ex1 + Alpha*(p1 - Ex1)\n",
        "                Ex2 = Ex2 + Alpha*(p2 - Ex2)\n",
        "\n",
        "                \n",
        "                # Collect data points for the all graphs\n",
        "                if NumG < 3:\n",
        "                    pts_y.append(p1[0])\n",
        "                    pts_x.append(p2[0])\n",
        "                    V1  = V1 +[Val1]\n",
        "                    V2  = V2 + [Val2]\n",
        "                    Itr = Itr + [It]\n",
        "                else:\n",
        "                    pts_y.append([p1[0], p2[0]])\n",
        "                    pts_x.append([p1[1], p2[1]])\n",
        "                    pts_z.append([p1[2], p2[2]])\n",
        "                    V1  = V1 + [Val1]\n",
        "                    V2  = V2 + [Val2]\n",
        "                    Itr = Itr + [It]\n",
        "\n",
        "            # Show the trial's execution time and the final policies and calculated values for each player.\n",
        "            print('Finished in %.4f seconds: ' % (time.time() - start))\n",
        "            print('Final policy:\\n  player 1',np.round(p1,4),'\\n  player 2', np.round(p2,4))\n",
        "            print('Value of policy:\\n  player 1: %.4f \\n  player 2: %.4f \\n' % (Val1, Val2))\n",
        "\n",
        "\n",
        "\n",
        "            # Labels for the plots\n",
        "            plotTitle = 'Trial %d' % (Trial + 1)\n",
        "            if Trial == 5: # The last trial starts at the equilibrium point.\n",
        "                plotTitle += '\\nInitial Equilibrium Point'\n",
        "\n",
        "            # Show a scatter plot of the policies, coloured by the iterations        \n",
        "            if NumG < 3: # For the first two games\n",
        "                title, yLabel, xLabel = GraphLabels1\n",
        "                im = ax[Trial].scatter(pts_x, pts_y, c=np.arange(Iteration), cmap='jet',s=25)\n",
        "\n",
        "                # Set the graph limits and labels\n",
        "                ax[Trial].set_xlim(0,1)\n",
        "                ax[Trial].set_ylim(0,1)\n",
        "                ax[Trial].set_ylabel(yLabel)\n",
        "                ax[Trial].set_xlabel(xLabel)\n",
        "                ax[Trial].set_title(plotTitle)\n",
        "\n",
        "                # Graph for Values of Players \n",
        "                yLabel, xLabel = GraphLabels2\n",
        "                im2 = ax2[Trial].plot(Itr, V1, 'r-', label = \"Player 1\")\n",
        "                im2 = ax2[Trial].plot(Itr, V2, 'b--', label = \"Player 2\")\n",
        "                ax2[Trial].legend(loc=\"upper right\")\n",
        "\n",
        "                ax2[Trial].set_xlim(1,40000)\n",
        "                ax2[Trial].set_ylim(-1.5,1.5)\n",
        "                ax2[Trial].set_ylabel(yLabel)\n",
        "                ax2[Trial].set_xlabel(xLabel)\n",
        "                ax2[Trial].set_title(plotTitle)\n",
        "\n",
        "                \n",
        "                \n",
        "            else: # For Rock Paper Scissor game, there are 3 Actions, so we need a graph for each player.\n",
        "                # Graph for Player 1\n",
        "                title, yLabel, xLabel, zLabel = GraphLabels1\n",
        "                im = ax.scatter(np.array(pts_x)[:,0], np.array(pts_y)[:,0], np.array(pts_z)[:,0], c=np.arange(Iteration), cmap='jet',s=30)\n",
        "                ax.set_title('Player 1 ' + plotTitle)\n",
        "\n",
        "                # Graph for Player 2\n",
        "                #ax.scatter(np.array(pts_x)[:,1], np.array(pts_y)[:,1], np.array(pts_z)[:,1], c=np.arange(Iteration), cmap='jet',s=30)\n",
        "                #ax.set_title('Player 2 ' + plotTitle)\n",
        "\n",
        "                # Set the graph limits and labels for both players\n",
        "                ax.axes.set_xlim3d(0,1,emit=True)\n",
        "                ax.axes.set_ylim3d(0,1,emit=True)\n",
        "                ax.axes.set_zlim3d(0,1,emit=True)\n",
        "                ax.axes.set_zlabel(zLabel,labelpad=0.7)\n",
        "                ax.axes.set_ylabel(yLabel,labelpad=0.7)\n",
        "                ax.axes.set_xlabel(xLabel,labelpad=0.7)\n",
        "                \n",
        "                # Graph for Value of Players\n",
        "                yLabel, xLabel = GraphLabels2\n",
        "                im2 = ax2[Trial].plot(Itr, V1, 'r-', label = \"Player 1\")\n",
        "                im2 = ax2[Trial].plot(Itr, V2, 'b--', label = \"Player 2\")\n",
        "                ax2[Trial].legend(loc=\"upper right\")\n",
        "\n",
        "                ax2[Trial].set_xlim(1,40000)\n",
        "                ax2[Trial].set_ylim(-0.5,0.5)\n",
        "                ax2[Trial].set_ylabel(yLabel)\n",
        "                ax2[Trial].set_xlabel(xLabel)\n",
        "                ax2[Trial].set_title(plotTitle)\n",
        "                \n",
        "        # Graphs are shown for each trial of games\n",
        "        fig.colorbar(im, ax=ax, aspect=30,  cmap='jet' )\n",
        "        # Update the title \n",
        "        if ExpectedValue:\n",
        "            title += ' With Expected Value Term'\n",
        "        fig.suptitle(title)\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
